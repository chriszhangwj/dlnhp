{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_code_tune.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "scylC1qNuBY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline code\n",
        "This code introduces a two-step training for the problem. It may be better doing only one-step, i.e. from noisy patch to descriptor directly, but this provides an initial valid submission to use as a first step.\n",
        "\n",
        "The outputs you see here are with only some minutes of training, so results should be better if the models are trained for more time.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initial check\n",
        "\n",
        "We first check the amount of memory we have in the notebook. Usually, we have available 11.4 GB of GPU memory, which is more than enough to run this code. However, some users reported having only 500 MB of GPU memory. If you have that amount, restart the environment to see if you get the corresponding 11.4 GB"
      ]
    },
    {
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "outputId": "e60c98b0-dc3f-46a0-d311-d8ac83c2dbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python2.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading functions and data\n",
        "\n",
        "The first step is to clone a GitHub repository with some functions implemented, and also downloading and extracting the HPatches data. We can run command line commands by using ```!```. Also, by using ```%``` we have access to the [built-in IPython magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-cd), which we use to change directory (`cd`). It takes around 5 minutes to download and unzip the dataset. \n"
      ]
    },
    {
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "outputId": "b57b9e47-1bb0-4a35-92f4-f1f16f039749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras_triplet_descriptor' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pyZSqhZ5LACT",
        "colab_type": "code",
        "outputId": "41ddb72b-d201-48b6-88f6-b04b5fb74f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "307CBCL-FjX4",
        "colab_type": "code",
        "outputId": "a70a1010-e449-4203-e107-a15e336c09b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "# !wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-31 11:29:23--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 185.235.236.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|185.235.236.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-01-31 11:29:23--  https://imperialcollegelondon.app.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 185.235.236.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|185.235.236.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!F1wozFGY2VETtrR0tmGJOc2MJ8TldjmkVnlr3GPd9SDjIkKdmHvqZLdfjGikqXGLB-1o_BsOc1V9Gpo06O9-SEd28PESXT-mVJy6YdFPrcyEBaWuIyn_RSqhbdnqYnukjS8LyHiblTXGtJ8qwqdmxYtDxxzH7v5pd8esdF2t5N86ODt_fnui-926zqh_PYYSpB1C3x7TqCFnUyJcRz9KYCldMSLAr8uGNfjroeeE8H2nZC57pLkjEkuly400nM-2ahcM-beeKTjHjkUVQMgJyY0FcaaREabgcwHwFL-OMTFHcWXkE1zZj4zFRo4BmeG09ej0z2n-bfzxUbTKtwZW_bkq9B1dmU6fAij0DF7imSruzZm6TnivZKkucixLwJmVBuEwstANZ_UrcHbJcP3jc9A6L4ytaZs6Lh4zHHHefUZ4ot6-LCghgqmcwcjCjErPXdDOnvCLthn8HfxUPj-k27nii2C_5MBzDiJae76trJGE69L2r_3CSa_xx5K5oSHn3yx0FX_K6wT2_ZcuzIzqU02o3w2kYFl_MKaD54todAQMMCinplPG1fYHpKf1WNgd-RPHRJAEr92QrKRWjtTfHKrQ1O-pnm4OlaMw3dks6uSG5d5ewrRIjX0ZTBDfYR-zFkKlImZDEFXhtIFwVVDCHyIehGwZTN3M7juVCKQgxsGdj6zYQ3G0VaQkyTgUvugqBK4oT5DQfMjmfX0Ze1rvR1HGiEI8RTmX56Kaq4NAHSEvpg9N7_gO9VxjWHbdAJDO_J0wG7EWLPfKramlkeIiyBAWW3_Z_68bZbWUziwyMP5gqGQWjb7U_urJtbXpQOA4V8r5cyK9cD9zMBgraxz29PeiQyKyz27fxn4nieirkd0yKJY0H-jme57iLKxwjkZdF4A_Nw-NqICLyVvZB7Jeonv_qIeMVBZnslj4Wah3iuazQfMFaDBahzWiZCkQvOdgYiLOZAfn6t-nzxXCFbadlpfcQKmyH0zU9rfgzUMYRDxn2uYuUDr0p14MfPsUgYvQcl9KXcOcbPUYPJvWfPMUuyRcOOr_niWBn77QEXjUJLuiyGUH_YRJ0VpMXuAsqYC8euZi3W1Jyy0xQl8alsCiUgHlMljTR9kOp4M2CfyoNARMUq9ZYPFJsPHI2_dHbDtzQwKVFFaT7kF77pkfg94Y9xCj9citrbdZZpE2KiyiKt4dEfgfr9EVHq9HjF-Oel3Grefm1Xka1opxroC1K0GE-A0ivbxgsRNVj_yUv2UIT45hKqZQe7aScW3CEBkuGQo3nsIsMtgZtOtcS6jMXB6KfqKy3tr9INW-4Y5BLaiYjjWKdyvtBJhoaaVmDOV1rzajivg5vD0TP8ZZqKBRksH4qJrPEIxsjh2P0o01I3PavinXEGNV_r6iBzsCS2H02v5bCIbQZ090CgemMBeAU_YCBXh3ufpnzrvbXZEbVgYaHVKJG8kp/download [following]\n",
            "--2019-01-31 11:29:24--  https://public.boxcloud.com/d/1/b1!F1wozFGY2VETtrR0tmGJOc2MJ8TldjmkVnlr3GPd9SDjIkKdmHvqZLdfjGikqXGLB-1o_BsOc1V9Gpo06O9-SEd28PESXT-mVJy6YdFPrcyEBaWuIyn_RSqhbdnqYnukjS8LyHiblTXGtJ8qwqdmxYtDxxzH7v5pd8esdF2t5N86ODt_fnui-926zqh_PYYSpB1C3x7TqCFnUyJcRz9KYCldMSLAr8uGNfjroeeE8H2nZC57pLkjEkuly400nM-2ahcM-beeKTjHjkUVQMgJyY0FcaaREabgcwHwFL-OMTFHcWXkE1zZj4zFRo4BmeG09ej0z2n-bfzxUbTKtwZW_bkq9B1dmU6fAij0DF7imSruzZm6TnivZKkucixLwJmVBuEwstANZ_UrcHbJcP3jc9A6L4ytaZs6Lh4zHHHefUZ4ot6-LCghgqmcwcjCjErPXdDOnvCLthn8HfxUPj-k27nii2C_5MBzDiJae76trJGE69L2r_3CSa_xx5K5oSHn3yx0FX_K6wT2_ZcuzIzqU02o3w2kYFl_MKaD54todAQMMCinplPG1fYHpKf1WNgd-RPHRJAEr92QrKRWjtTfHKrQ1O-pnm4OlaMw3dks6uSG5d5ewrRIjX0ZTBDfYR-zFkKlImZDEFXhtIFwVVDCHyIehGwZTN3M7juVCKQgxsGdj6zYQ3G0VaQkyTgUvugqBK4oT5DQfMjmfX0Ze1rvR1HGiEI8RTmX56Kaq4NAHSEvpg9N7_gO9VxjWHbdAJDO_J0wG7EWLPfKramlkeIiyBAWW3_Z_68bZbWUziwyMP5gqGQWjb7U_urJtbXpQOA4V8r5cyK9cD9zMBgraxz29PeiQyKyz27fxn4nieirkd0yKJY0H-jme57iLKxwjkZdF4A_Nw-NqICLyVvZB7Jeonv_qIeMVBZnslj4Wah3iuazQfMFaDBahzWiZCkQvOdgYiLOZAfn6t-nzxXCFbadlpfcQKmyH0zU9rfgzUMYRDxn2uYuUDr0p14MfPsUgYvQcl9KXcOcbPUYPJvWfPMUuyRcOOr_niWBn77QEXjUJLuiyGUH_YRJ0VpMXuAsqYC8euZi3W1Jyy0xQl8alsCiUgHlMljTR9kOp4M2CfyoNARMUq9ZYPFJsPHI2_dHbDtzQwKVFFaT7kF77pkfg94Y9xCj9citrbdZZpE2KiyiKt4dEfgfr9EVHq9HjF-Oel3Grefm1Xka1opxroC1K0GE-A0ivbxgsRNVj_yUv2UIT45hKqZQe7aScW3CEBkuGQo3nsIsMtgZtOtcS6jMXB6KfqKy3tr9INW-4Y5BLaiYjjWKdyvtBJhoaaVmDOV1rzajivg5vD0TP8ZZqKBRksH4qJrPEIxsjh2P0o01I3PavinXEGNV_r6iBzsCS2H02v5bCIbQZ090CgemMBeAU_YCBXh3ufpnzrvbXZEbVgYaHVKJG8kp/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  16.9MB/s    in 3m 50s  \n",
            "\n",
            "2019-01-31 11:33:14 (17.0 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "36mBTFvPCxY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "# !unzip -q ./hpatches_data.zip\n",
        "# !rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rjyr96hR_4wS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing necessary modules\n",
        "\n",
        "We now import the modules we will use in this baseline code. The read_data and utils imports are function provided in the repository we just cloned."
      ]
    },
    {
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AFG0LyAct_-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "outputId": "f3efb604-5c46-43fd-ca26-c0392901c741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u'/content/keras_triplet_descriptor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "_OqFkNujBGzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The HPatches dataset has several splits, where it separates the sequences available in train sequences and test sequences. We load the split 'a'. "
      ]
    },
    {
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in test_fnames, seqs)) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models and loss"
      ]
    },
    {
      "metadata": {
        "id": "LYJz8BDzBkIx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now define three functions that define main modules of our baseline. First, we have a function that returns a denoising model. The input for the function is the size of the patch, which will be 1x64x64, and it outputs a keras model.\n",
        "\n",
        "Then we have a similar function for the descriptor model, the model we use as baseline takes as input a patch of size 1x32x32, and returns a descriptor. Then we will use the triplet loss.\n",
        "\n",
        "You can modify the models in this functions and run the training code again for your new models. For example, the given UNet is quite shallow, maybe using a deeper network can improve results. Or testing new initializations for the weigths. Or maybe adding dropout. Or modifying the loss somehow...."
      ]
    },
    {
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "outputId": "8f2cf5bb-3432-42b3-8a2a-76a19791d01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model(shape):\n",
        "\n",
        "    inputs = Input(shape)\n",
        "    if mode==0:  # baseline\n",
        "      conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "      ## Bottleneck\n",
        "      conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "      ## Now the decoder starts\n",
        "      up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "      merge3 = concatenate([conv1,up3], axis = -1)\n",
        "      conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "      conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "      \n",
        "      model = Model(input = inputs, output = conv4)\n",
        "      \n",
        "    else if mode==1: # u-net\n",
        "      conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "      conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "      conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "      conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "      conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "      conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "      pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "      conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "      conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "      drop4 = Dropout(0.5)(conv4)\n",
        "      pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "      conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "      conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "      drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "      up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "      merge6 = concatenate([drop4,up6], axis = 3)\n",
        "      conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "      conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "      up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "      merge7 = concatenate([conv3,up7], axis = 3)\n",
        "      conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "      conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "      up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "      merge8 = concatenate([conv2,up8], axis = 3)\n",
        "      conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "      conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "      up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "      merge9 = concatenate([conv1,up9], axis = 3)\n",
        "      conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "      conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "      conv9 = Conv2D(2, 3, padding = 'same')(conv9)\n",
        "\n",
        "      model = Model(input = inputs, output = conv9)\n",
        "      \n",
        "    else if mode==2:\n",
        "      \n",
        "    \n",
        "  return model\n",
        "\n",
        "\n",
        "def get_descriptor_model(shape):\n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0 # _alpha is the margin parameter\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "\n",
        "print('finished')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RlS5zcV7EJgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoising patches\n"
      ]
    },
    {
      "metadata": {
        "id": "wHxHwjUd3-pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the DenoiseHPatches class implemented in the read_data.py file, which takes as input the list of sequences to load. It outputs batches where the input data is the noisy image and the label is the clean image, so then we can use a mean absolute error metric (or MSE also works) as loss function. \n",
        "\n",
        "Here we take a subset of training and validation sequences by using random.sample (3 sequences for training and 1 for validation data). The purpose of doing so was just to speed-up training for generating faster the output of this notebook. Remove the random.sample function to give the generator all the training data."
      ]
    },
    {
      "metadata": {
        "id": "m_VPSHmSK0dS",
        "colab_type": "code",
        "outputId": "601337b7-9bc7-4969-ec52-430077e47d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n",
        "# denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 5), batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 76/76 [01:03<00:00,  1.19it/s]\n",
            "100%|██████████| 40/40 [00:38<00:00,  1.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-eUSba93Dttj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shape = (32, 32, 1) # input image dimension\n",
        "denoise_model = get_denoise_model(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3wkjkpk4bRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We set number of epochs to 1, tweak it, along with other hyperparameters, to improve the performance of the model."
      ]
    },
    {
      "metadata": {
        "id": "gwMIXs03vKv6",
        "colab_type": "code",
        "outputId": "ce632004-d152-4e9c-da8d-c6b9f816721c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Gen RAM Free: 7.7 GB', ' | Proc size: 6.0 GB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "edwbgE6yKqcD",
        "colab_type": "code",
        "outputId": "6789df84-3b97-4517-a3a0-7fda139262b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "adam = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=adam, metrics=['mae'])\n",
        "#denoise_history = denoise_model.fit(x=seqs_train,epochs=1,verbose=2,validation_split=0.25)\n",
        "denoise_history = denoise_model.fit_generator(generator=denoise_generator, epochs=1, verbose=1, validation_data=denoise_generator_val)\n",
        "denoise_model.save_weights('denoise_adam_mae_epoch1_lr1e-3_bet0.9_bet0.999_ep1e8.h5') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "22482/31179 [====================>.........] - ETA: 41:02 - loss: 8.3058 - mean_absolute_error: 8.3058"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w36oCTYRC_gh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "denoise_model.save_weights('denoise_sgd_mae_epoch1_lr1e-4_momen0.9.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgSZb5_jhByI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0QMNjaG2lAM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ohb6Q94z4yya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may want to save the weights in your local disk. To do so, use:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GjAQRnPV47BI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('denoise_sgd_mae_epoch1_lr1e-4_momen0.9.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9FzSZzMEcs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization of denoising results\n",
        "To visualize how the denoised patches look, you can run the following function. It returns the noisy patch, the denoised patch in the middle, and the clean patch in the right side. "
      ]
    },
    {
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "outputId": "2a054336-91d2-4c11-f95a-517fa88f5a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACkCAYAAADWkiTuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXl0FFX6/l9WMYACIYlEBFlkkYAC\nsg+bIIKCICIwOSjIARGEo2dGkQGOjPM947C7cAYRHHBGR8CJoIMysoggCoRFQEBWh0UgA7LIEpOA\nsX9/cKp/9T630re706k0M8/nn/TTVV11q+pW33Q9933fEoFAICCEEEII8Y2Sxd0AQggh5H8NDr6E\nEEKIz3DwJYQQQnyGgy8hhBDiMxx8CSGEEJ/h4EsIIYT4TOloP/jyyy/Lzp07pUSJEjJ+/Hhp0qRJ\nLNtFiCfsd8Rv2OdIURDV4Lt582Y5evSoLF68WL777jsZP368LF68ONZtI0TBfkf8hn2OFBVRDb4b\nN26Url27iohInTp15MKFC3L58mWpUKGC5/q//vWvg6+nTp0qI0eOVMvLli2rdNWqVZX++eefPdvg\npl69ekqfPHlS6UcffVTptWvXKp2QkBB8PXPmTJk8ebJaXrq0ear69++v9PDhw5V2zpFDdna20t27\nd1d6wYIFSg8ePFjpy5cvB1/37dtXlixZIjk5OSHb6T4uEZEaNWooferUKaUPHTqk9IULF5ROTU0V\npEqVKkofOXJERERGjhwpb7zxhvz0009q+ZQpU4xthEOk/a5FixYiIrJo0SIZOHCgsd6VK1dCajy3\nIiJXr15VGvsunv/KlSsrXbFiRaWd6zN16lQZO3as0Ua8fiIiN9xwg9J5eXlKly9fXmncJrYJNR6T\n8/m2bdvKhg0bPLeJ+yxTpozSN954o9L5+flK5+bmKv3jjz8qjccsIlKypHbNsrOzpXnz5rJt2zYR\nEbl48aJa3rNnT2MbNiLtcyIiycnJIiKybt066dixo3E+8dwguL4Xtm3Y1nf28d5770l6errceuut\narlzDG4qVaoUcp1Il6PGc+rcSykpKcHvKewHBR1XQctt5w3v73DXKVeunNGHHbzuYZEoPd8zZ86o\nG7ZKlSryww8/hPXZ2267LZpd+goOUPEIDnjxiNcNXBii7Xd16tSJaTuKguvhvgg14MQL+E9AYSnM\nd13Dhg1j2pai4Hq4NyL9R6M4wH8EwyFqz9eNLUPl1KlT1ZfLxx9/HIvdFoqxY8eGXD579uyIt7l3\n795omyMi5i9pG8OGDSvU/vxg0qRJRbZtW79btGhR8Mtly5YtRdaOWLFw4cLiboKVbt26FXcTrHTo\n0MF4L1bfOeFk4123bl1w4D19+nRM9luUZGZmFncTrFSvXt2X/YQz0Be0jtcvXHzq5yaqwTc5OVnO\nnDkT1KdPn5akpKQC13/ggQeCr3ft2iU9evRQyy9duqQ0/sf45ZdfGtvE/9iysrKUtj26wfVTUlKC\nrzMzM+Wf//ynWv7KK68Y22jatKnSBw4cUBpPfMuWLZU+fvy40s2bN1d606ZNSrsf1WVkZEi/fv2M\nX+k7duxQ+vbbb1d6yJAhSm/evFlpfCyKeuvWrYLUrFlT6XLlyomIyIgRI+TNN9+Uc+fOqeW/+93v\njG2EQ6T97qGHHhIRkT179kijRo2C7SqIUDeKA/6HizdiqVKllL755puVxjY4esmSJdK3b1/j1yU+\nri3oPTd4zW666SalcR/YRvy8c4zdu3eXTz/9VETMLxp8HIiDFB637ZeC22JxtyHUPnNycqRVq1bB\nwQQtlWiItM+JiNxzzz0icu0xePny5a2PQsN5LB3Oo2jbNtw4TwgyMzOlVatWYT12xvcifaxseyxd\nUJ9KSkoK+2lDNOc2kuUi3o+dy5QpE3w/nEfXIlE+dm7Xrp2sWLFCRK59sSUnJ18Xj6TI9Q37HfEb\n9jlSVET1y7dZs2bSqFEjGThwoJQoUaJIHy0S4sB+R/yGfY4UFVF7vs8991ws20FIWLDfEb9hnyNF\nQUwmXNlw+6kiZtjP7t27lV63bp3SXmEG6HXic3b0hI8dO6Y0ehz33Xef0nPmzFEavVMR07OtXbu2\n0jgBCz1f9L1w/bvvvltpPKb+/fsbYVgnTpxQ2vE9HfA8YCgRtglDQrwm3Hz77bdKu0OqsrOzjbAR\nv8B2oKeEviRqr/AyPN94vmy+8i+//KK029u8fPmy4Rl7tQHvB/wMgh4xro/HhG10+2DOazxXGKaF\ny3EftuNE/93L88S+WaJEiZBt8gv3d1G4/l9hwfNj2697Vnj58uWNWeJek4ds4WSocX3U2Gav73kb\nNo/W1gfw83jevLZv+0y4ML0kIYQQ4jMcfAkhhBCf4eBLCCGE+Iwvni/G1L7xxhtKo1faqFEjpbdv\n325s00lz54D+D3pG6M1hrJ4TvyhyLT4VPSuv8AL0aNu1a6c0xqahH4teeFpamtLz5s1T+le/+lXw\ndf/+/WXXrl1GjHSnTp2URj/9lltuURpj7ZYuXao0euFffPGFIOgPub3ttLQ0zzhtPzh//rx6bfN0\nMT2cl3+LfiiC1wP7JcbQuvdRunRpwwsNJ60ierqY/Qy9NVvMLe7T7dc6r9HDtcVT4vqYEhPbgKk9\nvc57QbHCjgdn89+LCj8830izPuE9avN8MeWoiD1uFz8TqQcc6piizXIVaXx0OMTqmvKXLyGEEOIz\nHHwJIYQQn+HgSwghhPiML54vPq9v3bq10h999JHSGA975513GttEfwH9HYxnPXr0qNLovTll8Bww\nzzJuT0Skbt26SmOZQozTXb9+vdJYlBtz7GI8NJ7HGjVqGL4z+uNt27ZVesmSJUqjB4zro3eO50nE\n9Ozd8c/Hjx8PlvbzG7ffmp+fb+QLtsU2esXYos+IsaWFzR2LvjR6xiJm7CL2ffRH8TjQB7Plinbv\nz3ltayf6YniebF4cft4r7zYeZzjlGP3APZ8kKSnJOBZbKctYgOc3lN9avnz5kJ6wg83jxeW4TdTX\nQ7WioozT5i9fQgghxGc4+BJCCCE+w8GXEEII8RkOvoQQQojP+DLhCic3YYIMXL5nzx6lvSZOYPKI\n3r17K40TYzp27Kj0d999pzROPPrzn/+stFdhhc6dOyv94IMPKo0FB7C4NyYaePHFF5Xu169fyP3d\ncsstxmQbTOzxzTffKG0raN2gQQOl8Vp17dpVkE2bNintTvJQXEUVRPT5zcvLMxJYeE1mcoOJIUTM\nBBY46ceWJAMnN7knnZQvX964nlWrVjXagBNVMGEMbgMnXNmKQ4QqxOBs21aAAycR4XmxTdgKpwh6\nQRPNnL8FJeEoatz3VHJysirwISKG9oNQ57NMmTLGZDWvCVe2a2IrZI/3QjhFDGxtKCy2NoQz4erK\nlStSqVKlAq9rQRP/+MuXEEII8RkOvoQQQojPcPAlhBBCfMYXzxfBhBfVqlVTGj3gkydPGtvABBQX\nL15UGj3chQsXKp2amqo0epMjR45UGr0+ETPwH/3WuXPnKo1JOerXr690enq60pik49y5c4beuXOn\neg8TdWACDPQf8LgOHjyoNJ4nL18DvTd3gYi0tDTD6/YL9N7Qv0FvEz1CryQbCB47eka4PFTB8JIl\nSxpt8kqAcdNNNymNPhj6qXjN8f5CzxjXdycncRIroKfrlQTDDfrMmHQDNYLHJGJeH8c3dtYN5/r5\nga2IfFEk2bAltEDPF4lFAoxI/dlwPGA8V0XtAYdzbZzPOH9xLg/Os3HgL19CCCHEZzj4EkIIIT7D\nwZcQQgjxGV9MkerVqyuNRef//e9/K40F3A8dOmRsE33jw4cPK42F0du3b6/0mTNnlH777beVRg8Y\ni6SLmJ7Ea6+9pnSXLl2Ubtq0qdLoY2GMLYK+9sWLFw0/AWNux48frzTG/e7YsUNpjPu97bbblPaK\nd8YE606BiW7dusnatWsNb9sv3P2uevXqxvlDLw5jTb38WfQR0ZO1FRDAeFe3/1qpUiXDs/dqA3q+\n2A+xTbg++tDYJvS+3dp5jceFXhnGPyO4T5sP6hVvidtw1nH2jcuLi0iLbcQimb+tcL37fJctW9aX\nIgfohYaa/1BURHquvTxlmw8c7nHxly8hhBDiMxx8CSGEEJ/h4EsIIYT4jC+eb61atZRGj7dTp05K\nY95ljJ8VERkzZozSs2bNUhpzlXbo0EHp2bNnK/36668HX8+bN08OHDiglj/yyCNGG3bt2qX0U089\npTQ++0ff5fvvv1c6JSXF2Iebbdu2GRp95UaNGimdkZGhtC3vL8Z8og+KnrGI6cm7/fRDhw4Z/vrg\nwYONbRQFbu/zxhtvNLyaxMREpdGTwnMlYvo96NtjPCv6jqHyJpcqVcrwW728U3wPNW4D24AxoLgc\nz4N7+85r9M7wXGLcr62NuD2cY4FtEjFjzh2/3dmXV27ueMDmO3r5rzZvEq+pzfN1r5+QkGD18L2w\n5XaOhzjrSP12xOs84LlytHOOw43b5i9fQgghxGc4+BJCCCE+w8GXEEII8RlfHsqjl4kxt+ivYm3e\nf/zjH8Y20eNFfwHjdDdu3Kg01t49duyY0o899pjSGAcsYsYWN2vWTOnly5crXa9ePaXxPCxbtixk\nG2vWrGnojz/+WL1Xo0YNpdFf79u3r9Lnz59X+sKFC0ofP35cafRvRUQGDRqktNtHGT16tCxZssT4\njB+4PfcbbrjBmhMZvRovzwq9SvR8UWO8OeZVdnvq+fn51hzH4bQBjxPnP2A+b/S9MB7aKw+wzdvG\n+Q64HD1gPNe43Ou8oA/stMn565UP2g/cPmEsYnZjQahau15xvl71fG05qm15lm3xr37EGkfq8YbT\nJvxMuPmm+cuXEEII8RkOvoQQQojPhDX4HjhwQLp27SrvvvuuiIhkZWXJY489Junp6fLMM88USUks\n8r8N+xwpDtjviF9YPd+ffvpJ/u///k/atGkTfO/111+X9PR06dGjh8ycOVMyMjKMWrRu3HVtn3nm\nGcnKylLLGzZsqPTkyZOV7tOnj7FNjJHFWGCM0cQ6tXv37lUa/Vf0KYcMGWK0Yf/+/UovWrRI6V69\neim9e/dupTEWEv1XbEOTJk2UTkpKMuJ8MRa4ZcuWSqNPjf5f69atlUYfunnz5oJgnm3nvHTo0EE+\n+eQTI87bRiz6nIj2W3Nzcw2v1BazG84XLXqZ6BHZvFB3Py1XrpwRV+3lO6P/iR4vfgbbgJ/HGFFs\ng/s8Ou1Fn8u2DTxu/Dye+5ycnJDLvfaBdVUjHShj1e/c8cfZ2dkh/dZoiXSbkeYwDqfGL15z1DYi\nOYZY1e0tCg/eOY5IPWvrL9+yZcvKvHnzVML9zMzM4Jd+586djclMhBQG9jlSHLDfET+x/vItXbq0\n8Z90Tk5O8D+RxMREzwxUhEQL+xwpDtjviJ8UOtQonOn8H374odxxxx1BvXTp0pDrv/rqq4VtVqH5\n6KOPfN+n1+P1UIwePdp4D9NoFhb3I7homDJlSoxa8v8JN4RkwYIFUrt2bRERWbduXczbEWuwJGVx\ngVaEm+IqDxkJPXv2NN5D+yQawu13q1evDpYHxVC9eARtvngk0kfaxUGkaUGjGnwTEhIkNzdXypUr\nJ6dOnTJqwCJDhw4Nvl6/fr00btxYLW/RooXS6GFhrKqImfsVc+ZivujNmzcrjSfKHR87ZcoUef75\n59Vyr/94W7VqpXTHjh2VXrBggdI4MH711VdKf/DBB0ovXLhQaXde5aFDh8r8+fMNvxw9XfSZMQ9z\nv379lF69erXSeG3OnTsnCHq+Tn7ol156SSZNmmT4xA899JCxDRuR9jkRkWHDhomIyJo1a+Tee++1\nro8+o5ffit6l7UsBfWbsp04t5NmzZ8uoUaOMgQ9rJYuIUcM5NTVVaczPjW3ENmANYYyxde61WrVq\nBfsXroP3LA5U6DNjXmZcH2ONveppYwx1dna29O7dO/iPcyzifKPpd127dhWRawNv9erVrV5gOH6m\nLY8ybgP7CPYjp4/MmjVLxowZYxyX1zwNXAf7He4TwXsnXM83ISEhOD8m0nq8RVEr2YtQbSyIqEKN\n2rZtKytWrBARkZUrVxqTlQiJNexzpDhgvyNFhfWX7+7du2XKlCly4sQJKV26tKxYsUKmT58u48aN\nk8WLF0tqamrEj0sJCQX7HCkO2O+In1gH37S0NHnnnXeM9/GRKiGxgn2OFAfsd8RPfMntjM/A0dc6\nceKE0uhbetU0xYlAp0+fVrpq1apKY8wtekhr165V+ssvv1TaK853/fr1SqPPjF4axh2i97Z9+3al\nf/Ob3yjdtGlTpfPy8uSzzz5T72H+6Pvvv19pZwKSA14LjCXGeGivyTjoo7jP7aVLl+T9999Xy6Px\nfKMB24H+K+YnRg/Ry4PCbaCfit6nLaexO19u+fLljfh03J5I6FhhEfN+Q78V48nxPOA1dmvntS0e\nGY/TVlvXFoONy73Wcdrk/PUjV3A4RJMvOFJs28RzhbHI2Eb05L22gZ/BvAWxis1NSEgI7hvbUNj4\nZhvhxoqHamNBXjjTSxJCCCE+w8GXEEII8RkOvoQQQojPcPAlhBBCfMaXCVc4KeW+++5TGgu0b9q0\nSWmvST6YeAMLPe/YsUPpzz//XGkMIseCBLfccovS06dPN9rwt7/9TekvvvhC6VdeeUXp5cuXK40J\nMN5++22lsciBexLYyJEjZcuWLdKtWze1DmaU+v3vf680TqRwYhgdcMIWThbwSir/9NNPK+1OqpGQ\nkCDNmjUzPuMH7oQg586dMyYvYVINnDDiVVAcwclPOBEJJ8KEWj8/Pz+spACYMME2qQQn9uFkQ+wT\nFSpUUDoxMTH4GicROuC5xPOAy3FyG4KTxLwSnuAkLmdym/M3VhN+IsV9DcOZXBXpJCIvwpkw5caW\nECMcbPtAvK6hGzyGvLw8EbnW1suXL3t+Bu8npDgm3YU7yYu/fAkhhBCf4eBLCCGE+AwHX0IIIcRn\nfPF8s7KyQi7HovGYGN7Ln9iyZYvS6CfYCrhjIo+0tDSl0Zd+5JFHjG2gp/vEE08o/dhjjymNlZJw\n+cGDB5Xes2eP0pi44JdffpGBAweq9+666y6lMcGFU5vUARN3rFy5Uum6desqvWHDBkHQo3InNOnV\nq5fhv/uFu11ly5Y1vEyvxPxuvBI7IHhN8DPYL0MVlb969apcuHBBLfcK8sdtYiIPLEqA/in6YOjP\novftJOWoXLly8DVuE4sYeBXgCNUG9Mlw+16JdgryfB3Q676esfmIuBznK+By7HfhJpMoDHi9bH6t\ne7nz2vGBHVDjPmz3X3EkPHHgL19CCCHEZzj4EkIIIT7DwZcQQgjxGV88XyzCjEUQ0M/5+uuvlfaK\nD8Nk8uhp9O7dW+nMzEyl0e/DQgzoQ2O8rIgZEztnzhylT506pfRvf/tbpdu2bat0hw4dlJ40aZLS\nn376qdKHDx+WiRMnqve6d++uNHrAc+fOVRoLYqNXh943FpMQEfnxxx+VXrZsmYiItGrVSpYtWybH\njx9Xy0eMGGFsoyhAXwtjBbHAQDi+F8asYz+0xQajJ+XeZ3Z2thEPizG9IqbHjp5tKH9PxDwG9KnR\nM3b83MqVK8vZs2dFxIwFxnsYjwOXoy9mW98rphQ9Xue4nL9eRSn8AOcaILZ+5rUct2Mr1oDnK5QH\n7OX5ep3vSLYpEpv4ZcTmE0eKH0UvCoK/fAkhhBCf4eBLCCGE+AwHX0IIIcRnfPF8v/nmG6WPHj2q\ndP/+/ZXGPMvoGYqYMbWHDh1SesGCBUpjUXksXI9xihg/hjG5ImaMLHplEyZMUPrll19WGvMyL1q0\nSOlp06Yp/fzzzxsaY6gxpjYlJUVp9CgR9EDWrFmjtFfM9aOPPqp0w4YNg687d+5szelaVLivYV5e\nnhE7ih4UtrNixYrGNjG3MXpEOJcAvUyMPXV/Pj8/37g+2A+9tokavTnsl5i3HPeJfusPP/wgItdi\nvp2c6vgZvH/Qj8Vtou+M/Q4/j9dOxPTDnW067xeX5xtpbudYYPMuQ3m62dnZxrwN9PRFTI/X5uHa\njh37djh+blGfz3DzMsfis/zlSwghhPgMB19CCCHEZzj4EkIIIT7jixmHsaJYixf9IvQW0B8SMf0G\njKndv3+/0hiTizmL0atr166d0m+88YbRBmxXgwYNlJ45c6bSDz74oNJ4HoYOHar0448/rrQ7xrZn\nz57y9ddfG/HIWAP4L3/5i9LvvPOO0mPGjFF6yJAhSq9du1Zp9OJEzPNw4MABEbmWR/rAgQOe3qkf\nuL3QnJwcwzfE+Fj0ubz8bVzHlj8Y94n+q7sfX7p0yTi/Xr6lLU4U4+ixb6O23W9uL87J+4z3X0H1\nVh3wHsd4Z5vni+uLFOyfO3/jNbdzNL5lYbxIEXMegPv6ZWdnG23y8nNxHew3kcb92oh1TK8X0fjO\nXvmkk5KSCqxvjLUKHPjLlxBCCPEZDr6EEEKIz3DwJYQQQnzGF88X8wFj7OmxY8eUrlatmtJefseq\nVauUbty4sdIYQ4u5m7EeMMYSYxww5lkWEZk1a5bSGHf43XffKY2+GNYQxs9jGzEHb8mSJWXAgAHq\nPczNjB4G5pfGesAYL41t2rdvnyAYQ+32FEuWLGmcB79wx+2WLl3a8KwwZhfx8ubwfKI3afNPsVau\n2wO+cuWKnDlzRi3H/NMioWOFvbQtBtdWE9WNE/Nrq+eL28R7GON+0X9Hz9Fr3gf67871dj7rFSN9\nvRLr+FaM840mrzleI2wjrl+QJxoO0V7LSD8XzX6cfhdpPgP+8iWEEEJ8hoMvIYQQ4jMcfAkhhBCf\n8cXzbdmypdIYu4h+D/pBw4YNM7aJMbJeMZlu/vCHPyj9yCOPKI35pzE2C3Mmi4j06NFDaYw1Hj16\ntNJYjxf92XvvvVdp9P8wh29+fr7hIWLOXfSE27dvrzTW93366aeVxjhfzAErYsbvuX3iypUrS5Uq\nVYzP+IHb2yxVqpRxbtCzwnOJ/dLrPfQ+vXx5N+jhus/n2bNnDT/WK1YV22CrMYxtxONEjzdUG5x7\nEz1ePE48t7hN9M7xnrddKxG7t11cYK1cxObRF3af4Sx3a684Xy9/1vH7HfCa4HewrQZxJISahxDL\n7YTj2xYUCxxpXDJ/+RJCCCE+w8GXEEII8ZmwHjtPnTpVtm3bJj///LOMGDFCGjduLGPHjpX8/HxJ\nSkqSadOmWctLERIJ7HOkOGC/I35hHXw3bdokBw8elMWLF8v58+fl4YcfljZt2kh6err06NFDZs6c\nKRkZGZKenh5yG24wvy3Gu6IvhnmaRUSWLl2qNHqVy5cvV7pVq1ZKo2d8xx13KJ2Zman0XXfdZbQB\nY4H79eun9Ouvvx5yH927d1f6j3/8o9LoU6N3evvtt8tbb72l3kN/HP29GTNmKH3p0iWlMRc05opO\nTk4WBK+XEyvcv39/2bZtm1H32EYs+hy2NTk52Rqji3HYXjVk0VfE84vbQC8Tl2P+acQr7hD9VWwn\n+qU4d8A2PyLU/pzXeFx4brGN6KXhcrwW4cT5Yhsc7XjieG1sxKrf2bB5n9F4wPiZSDxgr3W95nbY\n4nptywtDpHmhrwesj51btGghr732mohcmyiVk5MjmZmZ0qVLFxG5Vix948aNRdtK8j8F+xwpDtjv\niJ9YB99SpUoF/+vMyMiQDh06SE5OTvC/nMTERGMWHCGFgX2OFAfsd8RXAmGyatWqQL9+/QIXL14M\ntG7dOvj+kSNHAgMGDAj52X379oW7G0KCFKbPBQKBwMGDB4uyeeQ6Ys+ePWGvW9h+t3///qjaSP77\nOH36dIHLwppwtX79epkzZ4689dZbUrFiRUlISJDc3FwpV66cnDp1ytMHdOP2Ng8fPixdu3ZVyxs2\nbKg0eohesY42z3fDhg1KYz5p9BDc+1y1apXhz3p5vuhFo+c7b948pXGb/fv3V9p55OWAnq/bExw8\neLD89a9/jdjz/eKLL5RGz7d27dpKo+eL8dAiphd99uxZERGZMmWKvPDCC4bni/mkvShsnxMRefTR\nR0XkmjfftGlTq+eL3ijmGBcxc13jNgryIR2cc+PgnP8dO3bI3XffbezPyzfD840eL7YR/VX0fDEf\ndWJioufy4cOHB/s0roP3KMYiB8Arx2uBvjVuz8vzxeP+5ZdfJC0tTXbv3i0i5nGHQyz6Xa9evUTk\n2vdD/fr1resXZ9yv00ZbrV4Rc74H5kKoXr260rfffrvS2C+xHxbUL+vVqxesEV7Uk92ijfNNSkqK\n+KmIdU+XLl2SqVOnyttvvx08OW3btpUVK1ZI7969ZeXKlUbiBqRGjRpKY8H2RYsWKY03zVdffWVs\ns1atWkpnZGQoXbduXaUxWQQOKjgBCxNg4I0uItKmTRul69Spo/RDDz2k9N69e5XGpBt9+/ZV+sMP\nP1Ta3TkHDx4smZmZ0qBBA7XOzp07lcYJPthxmjdvrjQOrnjcmAhExCwgUa9eveDrNm3aRNwpY9Hn\nRPSXQ1JSktGv8B8w/IL3+vLGmxMHjQsXLiiNhe3xH0v3l+SpU6eMQQq/sETMggL4hYQTGm0JLvAa\n4zG6B0LnNW7TXUzDa5u25CT45Y/bD2cgddYpaFKYjVj1O3e/CmeiEK4TTkIR2wAdyQDuta5Xkg3s\ny7gODvh4XPidbRvwIz2P4RDp4B1p4oxIsA6+y5cvl/Pnz8uzzz4bfG/y5MkyceJEWbx4saSmpkqf\nPn2KrIHkfw/2OVIcsN8RP7EOvgMGDDBSFIqILFiwoEgaRAj7HCkO2O+InzDDFSGEEOIzvhRW6NSp\nk9Jbt25Ves2aNUqj94lGvogYXidOiHIMeodVq1Yp/fnnnyuNfkOzZs2U/uSTT4w24HENHz5cafwv\nulu3biE/37NnT6XRU0bf7OzZs3LnnXeq99ArGzFihNJbtmxRGj1I9D3RCz958qQg2AbH2+7Tp4/s\n3bu3UEW0C4OXV+kGJ5uhT+nlheE1QC8KvU/0yXA5LsPr5+V1YTIOPDbsyzZ/FduEyefd2nmN28Bi\nKdgmPNeR4pXwBD1d59o43mO0BdiLG69rbvOFI/WA3bpMmTJhFT2w+a7Y122eri1Jhxtn4ii2M5Jt\nxIpIE5oUBH/5EkIIIT7DwZeX1no+AAAPoElEQVQQQgjxGQ6+hBBCiM/44vlizOyePXuUbtSokdIY\nD+blM/7rX/9S2knm79CuXTulMZ716NGjSmP8KiYWHz16tNEG9LEwSLxixYpKo184YcIEpTH5CHos\nTz75pKEx1ywG9WMiECwYgX4sJtnA84pFMETMc+lOJPH9998bCRn8AosW4PlETxC9HC/PELeBcYDo\n/6Avif3Kvc/s7GwjhtcL7Ec20C9FzxhjaDE23J1cwfHUsJ2osY2o8VwX5N86eBVBx+Ny1nH+ehWq\n+G8hloUGvDzLcN7DBD54TbGvoyeMHjD6te5jdD5rSxCDxHMFKv7yJYQQQnyGgy8hhBDiMxx8CSGE\nEJ/xxfPFuF7Mj4p5lzFXsJf/gDG127ZtU/rbb79VGj0jTAq+fPlypWvWrKk0ep8iZgysk1DdAWON\nMSG+OweyiJmXGWMn3cfYpUsX2bZtm1FA4vjx40qjn56VlaW0u+iFiOljo1fepEkTQTBO++GHHw6+\nHjZsmKxYscL4jB+4cxxfvHjR6APod998881KRxMnih4wXvNQfu1NN91keFTRFAfA40Q/1StPuRvs\nA+6CE87rSL03jB/H/NGYExvPk1ee5oJyARd34XX3NYyV52g7pkiXu9t19erVsHJH2+JZ8X5CzzfS\n2ORQ2yoIWz+MJ/jLlxBCCPEZDr6EEEKIz3DwJYQQQnzGF88X47uwoDt6CVjTdNCgQcY20Sc+ePCg\n0ugJb9q0SemqVasW3GCPNp04ccJY58iRIyG3gb7YnDlzlEY/cMyYMUpv3rxZaa/YSowNbtiwodIY\ni4cFsbHWLvp96Mt4+bdYc/bdd98VkWv5sZ3XxYHbs83Ly7N6oZjj2CufsFcB91Cgz4W+stvTrVy5\nstH3vfxZmw+M3hteQ+wT6L9in3D7aI73huugp4u5nW1xvQjG6Hp55XhuMc7X6/oVB5F4myLh5Qq2\n1c5FQnnPV65cibhesNc6Nn8b+yX2Ify8Wxfk+dr2icttuaELg/N9E24NYP7yJYQQQnyGgy8hhBDi\nMxx8CSGEEJ/xxfO95557lEa/B/0K9AJeffVVY5voe/Xo0UNp9LVSUlKUxvhYjOtFD8sr5+7999+v\nNMb1Yhvd8a8iIocPH1Z6xowZSmMdY7fvPGrUKFm6dKkMHjxYrYP++ldffaU0xlhjjG61atWU3r17\nt9JeHiQehzs2uHbt2jH1VQoDer4FeYYOXt4broMebijfSsScB+A+N4mJicb2vWKN8T2MkcV+h/4r\n7gM9X9Tu2HDnNcZT4v2C8xmwTjESTRwr+sLOPhzfPNo6q4XF3dYrV64UuhaviN3jjfRYo6lJG+l9\njG207RM9YXetcec1bqO4aoW7wfslXPjLlxBCCPEZDr6EEEKIz3DwJYQQQnzGF88Xn9O7n+WL6By8\nIqYv9vjjjxvb/Oijj5Tet2+f0lhjNjU1VWmsGYw1hnfs2KE05jgWMT1ejEVErw3zQ2Nu5/vuu09p\n9K2xhvHly5cNjxdzVA8YMEBpzIF96623Ko3eN9b3veOOOwT54IMPlHbHud1www2yatUqtXzEiBHG\nNvwAfUesW4tzEbziadFvxW1ijB9uI5TfV65cOcMHC8d3xjbZYpEjjQnFeGkRkVOnTql10PfCfaIn\nbIsLRrxq8+J5cO4/5/gwbtsv3D6klyeJ70WT/9nml9r8Wffnr169Wqi8y+HsQ8R+3NgnvM4jbgO1\nLbdzNPHMNjC+PFz4y5cQQgjxGQ6+hBBCiM9w8CWEEEJ8xhfP1+Z1Yt5krJOLWkTktttuUxrjUTH+\nEv0frHuLccIYY+vl//Xs2VPpkydPKo0+MsY+btmyRWmstYv+xYMPPmjopUuXqvfatm2rtFcdYjdY\nz3f79u1KYwwvxmCLmF61Oyf1sWPHpFu3biHb4BeR5vr1uua2fNDoAWM/DOU5VahQwfDJvHIa4z5x\nHTzOcLzsUNtze1nOa/R40e/CeRy4T6xVbYsz9bp2BV0LxweM1IOLFVjPN9KY3HA8YOxHsa5j69VG\nmz9qm0uAn8f1cY5LNJ5vpN63LS7fi4LieiON9+UvX0IIIcRnOPgSQgghPsPBlxBCCPEZDr6EEEKI\nzxRLko0aNWqEXI4TJXCikog5uQmTYODEF9wGmv24Pk4QwclTIiLff/+90vXr11cakx80atRIaSx6\n0KlTJ6UXL16sNBY9uHDhgjHxDNtZt25dpRs2bKj0+++/r3TVqlWVxvOGk6tEzIQnCE6G84vk5GT1\nGidT4AQ3TP7iNYEC+2piYqLSuA9MHuEk/XdwTyQqWbKk0Q+9ChLg/YGJPbDd2CbbBCDcnruNBU1a\nw4kuuB62Ae8vTLCAxxjOhCvn3OLf4ibSgu9e2CZY2SY72SZ52T4fDpEk9vDSoSZL/fjjj577wPMQ\nadINBO8dvBdCEcm6IvzlSwghhPiO9ZdvTk6OjBs3Ts6ePSt5eXkyatQoadCggYwdO1by8/MlKSlJ\npk2bFlWKNEK8YJ8jxQH7HfET6+D7+eefS1pamgwfPlxOnDghQ4cOlWbNmkl6err06NFDZs6cKRkZ\nGZKenu5He8n/AOxzpDhgvyN+Yh18H3jggeDrrKwsSUlJkczMTHnppZdERKRz584yf/78kB0SE1bg\nc/m9e/cqXblyZaXRI/Z6D5Pkoz+KiTzQq3MXJJg2bZrhjXol+vjmm2+UxiIHHTt2VBp9avRT8byg\nB4wJMLZv3y4dOnRQ76WkpCiNvvJnn32mdK9evZRGX3ru3LlKr1+/XhD01tzX4tKlSxF7IbHocyKm\nV2lLqo6JH9D/FjE9XPQiUUeSyL1ChQpGgguvggIIep+2JBvoI2ObKlSooLTbN3NeozeGfQCTbOCv\nRTyuihUrKo3b9/J8MdmIc5zO30iTbMSq3+H5ijT5hBe2X9s2bzOU5xuuL4rbwHbbfGUEz0uo81SQ\n5xuqr3ptE9uIy8N5qoHfZ06bnL/hPhkJe8LVwIED5T//+Y/MmTNHnnjiieAOEhMTPbMeEVJY2OdI\nccB+R3whEAHffvttoGfPnoFWrVoF3zty5EhgwIABIT937NixSHZDSJBo+1wgEAgcPny4CFtGricW\nLlwY0fqF6Xf79++PuH3kv5Ps7OwCl1l/+e7evVsSExOlWrVq0rBhQ8nPz5fy5ctLbm6ulCtXTk6d\nOqVCOrwYO3Zs8PXChQtl1KhRanlmZqbS+NgZw2W8KOxj5zVr1gRf79mzR5599lm1PJzHzvjIAx87\n42OyDRs2KH3vvfcqjcfkfmy9evVq6dq1a8SPnbENkT52xnAqEZGzZ896tvvVV1+VZ5991nhMM2XK\nFGMbbmLR50REnnrqKRER+fTTT6V79+5GOAuGGuG58fOx83vvvSfp6enGY2e0MkTM/Nq4Tbx/bI+I\nbeFTziPh2bNnB+9dPDf4KBv3getjfnd87IyfDyfH9aVLl6Rv376yZMkSEYk8fCZW/c65p/bv3y/1\n69e3PvqMxWPnSMN8HJw2RkOktXBt6+P3p9OPly1bFjynSUlJah20NLE+OWq8fvidgI+xvcINvR47\nV6pUKfhoPGaPnbdu3SonTpyQCRMmyJkzZ+Snn36S9u3by4oVK6R3796ycuVKad++fchtYHFv9IPw\nBDoH4YAJt0XMQeLjjz9Wev/+/UpjB8OBrVWrVkrjCcai8iLmlzd6ugcPHlS6devWSqOvvG/fPqVT\nU1OVRo+4SpUqxj8Zq1evVhrPJd6EOFjs2rVLaRzMvYqD47nZunVr8PWVK1ekZcuWxmdCEYs+J6Jj\nSUuWLGl8geM1xgEEBwQRe2F6jF/FLxy8Md2DTJkyZYyb3cuPO3funNLon+L9hgMfngc87nAKUGAM\ne6hiDCLmYFqzZk2l8R8GbBMOtCLmuQ4UMr43Vv3Ofc29Bhxb3LUXNm8yUr81FkS6T9s/HV7fLQ5O\nDD7eD/g9XtjCC7g9HIxD4RwfHicO8A7WwXfgwIEyYcIESU9Pl9zcXHnxxRclLS1NXnjhBVm8eLGk\npqZKnz59wm4gITbY50hxwH5H/MQ6+JYrV05mzJhhvL9gwYIiaRAh7HOkOGC/I37CDFeEEEKIz5QI\nRGuQEEIIISQq+MuXEEII8RkOvoQQQojPcPAlhBBCfIaDLyGEEOIzHHwJIYQQn+HgSwghhPhM2FWN\nCsvLL78sO3fulBIlSsj48eOlSZMmfu3ayoEDB2TUqFEyZMgQGTRokGRlZcVVAe2pU6fKtm3b5Oef\nf5YRI0ZI48aN46p98VyEPF77Xbz3ORH2u2iJ1z4nwn5XWGLa54q+rkMgkJmZGXjyyScDgUAgcOjQ\noUD//v392G1YZGdnBwYNGhSYOHFi4J133gkEAoHAuHHjAsuXLw8EAoHAjBkzAn//+9+LrX0bN24M\nDBs2LBAIBALnzp0LdOzYMa7aFwgEAp988klg7ty5gUAgEDh+/HigW7ducdHGeO138d7nAgH2u2iJ\n1z4XCLDfxYJY9jlfHjtv3LhRunbtKiIiderUkQsXLhgJrIuLsmXLyrx581S1i8zMTOnSpYuIXCug\nvXHjxuJqnrRo0UJee+01EblW7D0nJyeu2idyrQj58OHDRUQXIS/uNsZrv4v3PifCfhct8drnRNjv\nYkEs+5wvg++ZM2dU1ZIqVarETVHq0qVLG1VgcnJy4qaAdqlSpYJVMTIyMqRDhw5x1T43AwcOlOee\ne07Gjx8fF22M134X731OhP0uWuK1z4mw38WSWPQ53zxfN4HrKKNlvLR19erVkpGRIfPnz5du3boF\n34+X9omILFq0SPbu3SvPP/+8ale8tDFe2mEjntrJflc44qEN4RJPbY33fheLPufLL9/k5GQ5c+ZM\nUJ8+fdooihxPJCQkBOuHhltAuyhZv369zJkzR+bNmycVK1aMu/bt3r07WNsYi5CLFF8br6d+F2/X\nVIT9Lhqupz4nwn4XKbHsc74Mvu3atZMVK1aIiMiePXskOTk5oiLFftO2bdtge8MtoF1UXLp0SaZO\nnSpvvvmmVKpUKe7aJ3KtCPn8+fNFRIJFyOOhjddTv4uH8+WG/S46rqc+JxJ/1zTe+10s+5xvVY2m\nT58uW7dulRIlSsikSZOkQYMGfuzWyu7du2XKlCly4sQJKV26tKSkpMj06dNl3LhxkpeXJ6mpqfKn\nP/1JypQpUyztW7x4scyaNUtq1aoVfG/y5MkyceLEuGifiEhubq5MmDBBsrKyJDc3V0aPHh0sQl7c\nbYzHfhfvfU6E/a4wxGOfE2G/iwWx7HMsKUgIIYT4DDNcEUIIIT7DwZcQQgjxGQ6+hBBCiM9w8CWE\nEEJ8hoMvIYQQ4jMcfAkhhBCf4eBLCCGE+AwHX0IIIcRn/h+L7KMK5Iou3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Descriptor Network\n",
        "Now we train the network that generates the descriptors for the patch. We are going to use the triplet loss, which takes an anchor patch, a negative patch and a positive patch. The idea is to train the network so the descriptors from the anchor and positive patch have a low distance between them, and the negative and anchor patch have a large distance between them. \n",
        "\n",
        "In this cell we generate a triplet network, which is a network formed by three copies of the same network. That means that the descriptor model will compute the descriptor for the input `'a'` (anchor), the same descriptor model (with the same weights) will compute the descriptor for the input `'p'` (positive), and again the same model will compute the descriptor for the input `'n'` (negative). "
      ]
    },
    {
      "metadata": {
        "id": "DVmDZIRTHPDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1) # input dimension\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en]) # arbitrary loss function as layer (by doing this we define our own loss function)\n",
        "\n",
        "descriptor_model_trip = Model(inputs = [xa, xp, xn], outputs = loss)\n",
        "sgd = keras.optimizers.SGD(lr = 0.1)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BllXKocHCwZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use the class HPatches, which loads the corresponding files by using the method read_image_file. It reads the clean patches, which are the ones used for training in this baseline code. The output of read_image_file is a tuple of the form (images, labels), which is passed to the class DataGeneratorDesc. This class is a generator that creates batches of triplets, and each epoch is defined by the number of triplets in the argument `num_triplets`."
      ]
    },
    {
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "outputId": "d6def37a-42ff-44ae-f592-7eabd5cec853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames = train_fnames, test_fnames = test_fnames)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 1), num_triplets = 100000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 0), num_triplets = 10000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 116/116 [00:36<00:00,  3.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "97435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:01<00:00, 85427.36it/s]\n",
            "100%|██████████| 116/116 [00:21<00:00,  4.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "59532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 83077.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoQYyuD7_4PS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a random triplet in the form of anchor, positive and negative sample"
      ]
    },
    {
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "outputId": "32b31410-95ea-443a-c361-e7d9ed108e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACkCAYAAADWkiTuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRJfeQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UaE2_6HUCAOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the descriptor model and save the weights afterward."
      ]
    },
    {
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "outputId": "86a272d9-3de9-489e-df3a-83352f9fa10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "cell_type": "code",
      "source": [
        "history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=10, verbose=1, validation_data=val_generator)\n",
        "descriptor_model.save_weights('hardnet.h5') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1680"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 75470/100000 [00:02<00:00, 28326.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 157s 78ms/step - loss: 0.1680 - val_loss: 0.2141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80245/100000 [00:03<00:00, 30527.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:04<00:00, 22564.77it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 58:55 - loss: 0.1496"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 2173/10000 [00:00<00:00, 21710.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 30:47 - loss: 0.1320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 4902/10000 [00:00<00:00, 23128.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 21:27 - loss: 0.1506"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 8712/10000 [00:00<00:00, 26218.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 16:44 - loss: 0.1564"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 26935.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1501"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 80389/100000 [00:02<00:00, 28419.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 159s 79ms/step - loss: 0.1501 - val_loss: 0.1845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 86665/100000 [00:03<00:00, 29851.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 97953/100000 [00:04<00:00, 6813.60it/s]\n",
            "100%|█████████▉| 99692/100000 [00:05<00:00, 8333.18it/s]\n",
            "100%|██████████| 100000/100000 [00:05<00:00, 19743.66it/s]\n",
            " 12%|█▏        | 1155/10000 [00:00<00:02, 3400.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 1:19:15 - loss: 0.2695"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 2866/10000 [00:00<00:01, 4476.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 40:56 - loss: 0.1748  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 6971/10000 [00:00<00:00, 6108.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   4/2000 [..............................] - ETA: 21:43 - loss: 0.1802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 15857.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1395"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 81606/100000 [00:02<00:00, 30762.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 159s 79ms/step - loss: 0.1394 - val_loss: 0.1685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87040/100000 [00:03<00:00, 35364.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:04<00:00, 23268.21it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 52:57 - loss: 0.1457"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 2287/10000 [00:00<00:00, 22860.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 27:46 - loss: 0.1353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 6472/10000 [00:00<00:00, 26462.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 19:24 - loss: 0.1024"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 31720.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 15:28 - loss: 0.0876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 80814/100000 [00:03<00:00, 29431.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 158s 79ms/step - loss: 0.1344 - val_loss: 0.1588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 84863/100000 [00:03<00:00, 31367.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 94149/100000 [00:04<00:00, 10744.96it/s]\n",
            " 96%|█████████▌| 96141/100000 [00:04<00:00, 12466.54it/s]\n",
            "  9%|▉         | 894/10000 [00:00<00:01, 8932.43it/s]\u001b[A\n",
            " 98%|█████████▊| 97764/100000 [00:04<00:00, 11716.44it/s]\n",
            " 99%|█████████▉| 99208/100000 [00:04<00:00, 11374.62it/s]\n",
            "100%|██████████| 100000/100000 [00:04<00:00, 20791.72it/s]\n",
            " 40%|████      | 4032/10000 [00:00<00:01, 5487.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 1:06:14 - loss: 0.0695"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6007/10000 [00:00<00:00, 6950.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 34:28 - loss: 0.0377  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 8324/10000 [00:00<00:00, 8797.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 23:53 - loss: 0.0486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 11031.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1292"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 79335/100000 [00:02<00:00, 31965.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 160s 80ms/step - loss: 0.1292 - val_loss: 0.1707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▎ | 83667/100000 [00:03<00:00, 32380.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:04<00:00, 22587.32it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 55:33 - loss: 0.0548"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 1782/10000 [00:00<00:00, 17815.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 29:15 - loss: 0.0627"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 5796/10000 [00:00<00:00, 21383.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 20:24 - loss: 0.0975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 30580.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 15:57 - loss: 0.0951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 78343/100000 [00:02<00:00, 29303.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 159s 79ms/step - loss: 0.1246 - val_loss: 0.1658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83322/100000 [00:02<00:00, 31330.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 90878/100000 [00:03<00:00, 10465.71it/s]\n",
            " 94%|█████████▎| 93711/100000 [00:04<00:00, 12907.00it/s]\n",
            "  8%|▊         | 767/10000 [00:00<00:01, 7666.24it/s]\u001b[A\n",
            " 96%|█████████▌| 95718/100000 [00:04<00:00, 11097.11it/s]\n",
            " 25%|██▍       | 2456/10000 [00:00<00:00, 7796.22it/s]\u001b[A\n",
            " 97%|█████████▋| 97374/100000 [00:04<00:00, 10966.79it/s]\n",
            " 99%|█████████▉| 98854/100000 [00:04<00:00, 10886.01it/s]\n",
            " 51%|█████▏    | 5136/10000 [00:00<00:00, 8569.05it/s]\u001b[A\n",
            "100%|██████████| 100000/100000 [00:04<00:00, 20935.63it/s]\n",
            " 68%|██████▊   | 6849/10000 [00:00<00:00, 6515.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 1:14:50 - loss: 0.0836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 9701.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1184"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 77361/100000 [00:02<00:00, 29778.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 159s 80ms/step - loss: 0.1183 - val_loss: 0.1602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82449/100000 [00:03<00:00, 34009.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:04<00:00, 23222.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 53:24 - loss: 0.1849"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   3/2000 [..............................] - ETA: 19:32 - loss: 0.1377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 3778/10000 [00:00<00:00, 37758.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 15:18 - loss: 0.1518"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 7112/10000 [00:00<00:00, 36314.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   5/2000 [..............................] - ETA: 12:45 - loss: 0.1375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 30669.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   6/2000 [..............................] - ETA: 11:16 - loss: 0.1186"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1129"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 83594/100000 [00:03<00:00, 31019.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 158s 79ms/step - loss: 0.1130 - val_loss: 0.1438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 87806/100000 [00:03<00:00, 33682.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:04<00:00, 22578.47it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 51:10 - loss: 0.0950"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 1369/10000 [00:00<00:00, 13686.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 26:57 - loss: 0.1337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 4786/10000 [00:00<00:00, 16687.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 18:52 - loss: 0.1725"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 7676/10000 [00:00<00:00, 19108.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 14:46 - loss: 0.1467"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 27068.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1108"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 76967/100000 [00:03<00:00, 29253.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 158s 79ms/step - loss: 0.1108 - val_loss: 0.1520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 81396/100000 [00:03<00:00, 30618.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:05<00:00, 19686.38it/s]\n",
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/2000 [..............................] - ETA: 58:02 - loss: 0.1329"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 4314/10000 [00:00<00:00, 43128.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   2/2000 [..............................] - ETA: 30:19 - loss: 0.0812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 7939/10000 [00:00<00:00, 40805.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   3/2000 [..............................] - ETA: 21:10 - loss: 0.0858"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10000/10000 [00:00<00:00, 35919.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   4/2000 [..............................] - ETA: 16:33 - loss: 0.0811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1113"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 81873/100000 [00:02<00:00, 30018.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 158s 79ms/step - loss: 0.1112 - val_loss: 0.1510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 93768/100000 [00:04<00:00, 10220.83it/s]\n",
            " 95%|█████████▌| 95378/100000 [00:04<00:00, 11310.05it/s]\n",
            " 11%|█         | 1072/10000 [00:00<00:00, 10709.85it/s]\u001b[A\n",
            " 97%|█████████▋| 96957/100000 [00:04<00:00, 11305.54it/s]\n",
            " 98%|█████████▊| 98401/100000 [00:04<00:00, 11384.58it/s]\n",
            "100%|█████████▉| 99759/100000 [00:04<00:00, 10678.93it/s]\n",
            "100%|██████████| 100000/100000 [00:04<00:00, 21062.23it/s]\n",
            "100%|██████████| 10000/10000 [00:00<00:00, 12841.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJ-r9D4hDxij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating descriptors files for test data \n",
        "\n",
        "HPatches benchmark takes as input the descriptors for the test data in a CSV form. This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to None), the descriptor is computed directly in the noisy patch."
      ]
    },
    {
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "outputId": "948f05aa-2dd5-452f-9730-29d3ac90e577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, denoise_model, seqs_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [06:26<00:00,  9.25s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0jFr05rE1oI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating descriptors in HPatches Benchmark\n",
        "We first download the official repository for HPatches Benchmark."
      ]
    },
    {
      "metadata": {
        "id": "r_53StvZE8MT",
        "colab_type": "code",
        "outputId": "5e3264b1-447c-499a-c71a-70bb85f5070f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hpatches/hpatches-benchmark\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hpatches-benchmark'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 1435 (delta 11), reused 14 (delta 5), pack-reused 1409\u001b[K\n",
            "Receiving objects: 100% (1435/1435), 239.72 MiB | 20.62 MiB/s, done.\n",
            "Resolving deltas: 100% (789/789), done.\n",
            "Checking out files: 100% (135/135), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script.\n",
        "\n",
        "### Verification\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "outputId": "5f03fe92-06d5-40b8-8c6d-3cdc29a2a99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=verification\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mverification\u001b[0m task\n",
            "Processing verification task 1/3 : 100% 1000000/1000000 [01:24<00:00, 11893.15it/s]\n",
            "Processing verification task 2/3 : 100% 1000000/1000000 [01:23<00:00, 12029.05it/s]\n",
            "Processing verification task 3/3 : 100% 1000000/1000000 [01:24<00:00, 11835.86it/s]\n",
            ">> \u001b[32mVerification\u001b[0m task finished in 260 secs  \n",
            "\u001b[32mVerification\u001b[0m task results:\n",
            "\u001b[34mCUSTOM\u001b[0m - Balanced variant (auc) \n",
            "Noise       Inter     Intra\n",
            "-------  --------  --------\n",
            "Easy     0.952802  0.927342\n",
            "Hard     0.935712  0.90286\n",
            "Tough    0.907797  0.866072\n",
            "\u001b[34mCUSTOM\u001b[0m - Imbalanced variant (ap) \n",
            "Noise       Inter     Intra\n",
            "-------  --------  --------\n",
            "Easy     0.884978  0.826117\n",
            "Hard     0.83224   0.748747\n",
            "Tough    0.752166  0.650537\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5290Bw-udJdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matching"
      ]
    },
    {
      "metadata": {
        "id": "EUqpwi87ckJv",
        "colab_type": "code",
        "outputId": "4be072c6-d192-4b84-fd70-3559776ac903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=matching\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mmatching\u001b[0m task\n",
            "100% 40/40 [02:12<00:00,  4.48s/it]\n",
            ">> \u001b[32mMatching\u001b[0m task finished in 132 secs  \n",
            "\u001b[32mMatching\u001b[0m task results:\n",
            "\u001b[34mCUSTOM\u001b[0m - mAP \n",
            "    Easy      Hard      Tough      mean\n",
            "--------  --------  ---------  --------\n",
            "0.329607  0.150999  0.0608267  0.180477\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXXgbN7DdMnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval"
      ]
    },
    {
      "metadata": {
        "id": "ZNmKIat1cn_M",
        "colab_type": "code",
        "outputId": "1cbce984-a732-430d-9027-e7cb84092c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=retrieval\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mretrieval\u001b[0m task\n",
            ">> Please wait, computing distance matrix...\n",
            "tcmalloc: large alloc 1600004096 bytes == 0x55a994f26000 @  0x7f5831f271e7 0x7f5827b28cf1 0x7f5827b8b3a2 0x7f5827b8d0de 0x7f5827c240e8 0x55a96e8f6fe5 0x55a96e8ecd0a 0x55a96e8f45fe 0x55a96e8f4232 0x55a96e8ecd0a 0x55a96e8f4c38 0x55a96e8ecd0a 0x55a96e8ec629 0x55a96e91d61f 0x55a96e918322 0x55a96e91767d 0x55a96e8c61ab 0x7f5831b24b97 0x55a96e8c5a2a\n",
            ">> Distance matrix done.\n",
            "Processing retrieval task: 100% 10000/10000 [03:58<00:00, 41.28it/s]\n",
            ">> \u001b[32mRetrieval\u001b[0m task finished in 257 secs  \n",
            "\u001b[32mRetrieval\u001b[0m task results:\n",
            "\u001b[34mCUSTOM\u001b[0m - mAP 10K queries \n",
            "Noise         100       500      1000      5000     10000     15000     20000\n",
            "-------  --------  --------  --------  --------  --------  --------  --------\n",
            "Easy     0.832393  0.718672  0.671093  0.560876  0.515329  0.489569  0.473572\n",
            "Hard     0.785755  0.620193  0.549975  0.392863  0.332639  0.300922  0.282002\n",
            "Tough    0.702068  0.484685  0.400712  0.239026  0.187053  0.161916  0.148025\n",
            "mean     0.773405  0.60785   0.540593  0.397589  0.345007  0.317469  0.3012\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_2fBzUB5RF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compressing and saving the CSV files \n",
        "\n",
        "We first compress the directory with all the CSV by using the following command. Remove the `q` option if you want it to output the progress."
      ]
    },
    {
      "metadata": {
        "id": "Lh_svT3p5Ww-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !zip -rq descriptors.zip ./out/custom\n",
        "!zip -r descriptors.zip ./out/custom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svoL779J8AJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generated .zip is quite large, the method we used for the weights does not work. We have two other methods. First, in the file explorer in the left column we can right-click in the file and then click download. Then, we will see a circle next to the file showing the download progress.\n",
        "\n",
        "The second way does not require for you to download the files, it save the zip file in your Google Drive account, and you can download it later to your machine if you want. To do so, follow this method (found [here](https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory)). First run the next cell, and the output will be a link for authentication purposes, and just follow the instructions"
      ]
    },
    {
      "metadata": {
        "id": "RjOmPv5z7Opx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "\n",
        "  media = MediaFileUpload(path, \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                  media_body=media,\n",
        "                                  fields='id').execute()\n",
        "\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "  return created\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfzjfMc59NKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the following function to save the file to your drive account. The second argument is the name of the file we want to save, and the first argument the name that will have in your Drive."
      ]
    },
    {
      "metadata": {
        "id": "UwrqWr_c7pAi",
        "colab_type": "code",
        "outputId": "39972cd1-8218-4f11-9e93-adf6c6f775ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1-e2KuQ39Lgc26EzcwVu3drBeBk4aKmFd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u'id': u'1-e2KuQ39Lgc26EzcwVu3drBeBk4aKmFd'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}